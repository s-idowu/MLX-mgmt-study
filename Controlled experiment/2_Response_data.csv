Timestamp;What is your current occupation?;What is your level of education?;How many years of ML experience do you have?;Do you have any experience with the Git version control tool?;If your answer is yes, how many years of experience do you have with Git?;Do you have any prior experience with any ML experiment tracking tools?;If your answer is yes, name the ML experiment tracking tools.;Write down your email address:;Select your group;Which of the 13 runs performed best? (i.e. which has the lowest RMSE score?);What is the RMSE value for that run?;Which of the algorithms (LR & RFR) performed best (lowest RMSE) in their first run?;What data features were used for the experimental run with the highest r2_score?;Compare Run 4 and Run 1, which one had the highest mean absolute error?;What was the value?;"Compare “EX-5” ,“EX-7”, ""EX-9"" and ""EX-11"" in the dashboard table. [Highest RMSE]";"Compare “EX-5” ,“EX-7”, ""EX-9"" and ""EX-11"" in the dashboard table. [Highest R2]";"Compare “EX-5” ,“EX-7”, ""EX-9"" and ""EX-11"" in the dashboard table. [Highest mean absolute error]";If we want to reproduce the results of previous runs, we need to retrieve the model. Which model was used for “EX-4”?;Query Neptune for the model with the worst RMSE (Largest value). Provide Run id, and the normalize parameter.;List all linear regression runs with RMSE value less than 6.5. Provide Run id, and the r2 value for that run.;In the python file, print the R2 value of the very first run. What was the value?;How helpful was the brief Neptune tutorial provided ahead of this experiment?;How do you rate the ease of completing the tasks?;How helpful is the visual dashboard provided by Neptune.ai when comparing the experimental runs?;How long did it take you to complete the Neptune.ai section?;Any Additional Comments:;Which run performed best, (i.e. has the lowest RMSE score)? ;What is the RMSE value for that run?;Which of the algorithms performed best in their first run? LR or RFR i.e. which one had the lowest RMSE.;What data features were used for the run with the lowest r2_score?;Between Run 4 and Run 1, which one had the highest mean absolute error?;What was the value?;"Compare “Run 5”, “Run 7”, ""Run 9"" and ""Run 13"": [Highest RMSE]";"Compare “Run 5”, “Run 7”, ""Run 9"" and ""Run 13"": [Highest R2]";"Compare “Run 5”, “Run 7”, ""Run 9"" and ""Run 13"": [Highest mean absolute error]";If we want to reproduce the results of previous runs, we need to retrieve the model. Which model was used for “Run 4”?;Return the run with the worst RMSE (Largest value);Find the runs that produced models evaluation metric, r2 is greater than 0.32;Where you used linear regression algorithm and the RMSE was greater than 1.15;What was the R2 value of the very first run?;How helpful was the short tutorial in the beginning in completing the tasks?;How do you rate the ease of completing the tasks?;How helpful were the DVC commands to compare the runs?;How long did it take you to complete the DVC section?;Any Additional Comments:;Which run performed best, (i.e. has the lowest RMSE score)? ;What is the RMSE value for that run?;Which of the algorithms performed best in their first run? LR or RFR i.e. which one had the lowest RMSE.;What data features were used for the run with the lowest r2_score?;Between Run 4 and Run 1, which one had the highest mean absolute error?;And what was the value?;"Compare “Run 5”, “Run 7”, ""Run 9"" and ""Run 13"": [Highest RMSE]";"Compare “Run 5”, “Run 7”, ""Run 9"" and ""Run 13"": [Highest R2]";"Compare “Run 5”, “Run 7”, ""Run 9"" and ""Run 13"": [Highest mean absolute error]";If we want to reproduce the results of previous runs, we need to retrieve the model. Which model was used for “Run 4”?;Run with the worst RMSE (Largest value);Where you used linear regression algorithm and the RMSE was less than 55;What was the R2 value of the very first run?;How helpful was the short tutorial in the beginning in completing the tasks?;How do you rate the ease of completing the tasks?;Describe how you manually track, query, and retrieve the experiment runs and their assets.;How helpful was the use of your manual technique in tracking/retrieving the experimental runs and their assets?;How long did it take you to complete the No-Tool section?;Any Additional Comments:;Describe your experience with each of the tools(Neptune, DVC and No-Tool).;The DVC and Neptune tools provide a significant support for tracking, querying and retrieving generated data from ML experiments over No-tool.;Please elaborate on your response above.;Which tool do you consider best for tracking data during ML experiments ?;Which tool do you consider best for querying and retrieving previously tracked data?;Which of Neptune and DVC do you consider least intrusive in completing the tasks?;Which of Neptune and DVC was the easiest to learn?;Which of the tools provides the best support for comparing different experiment runs?;Neptune helps compare different runs using a web dashboard, while DVC uses CLI. Which do you most convenient?;Please elaborate.;Finally, which tool would you recommend a ML practitioner to use?;Please elaborate.;Which run performed best, (i.e. has the lowest RMSE score)? ;What is the RMSE value for that run?;Which of the algorithms performed best in their first run? LR or RFR i.e. which one had the lowest RMSE.;What data features were used for the run with the highest r2_score?;Between Run 4 and Run 1, which one had the highest mean absolute error?;What was the value?;"Compare “Run 5”, “Run 7”, ""Run 9"" and ""Run 13"": [Highest RMSE]";"Compare “Run 5”, “Run 7”, ""Run 9"" and ""Run 13"": [Highest R2]";"Compare “Run 5”, “Run 7”, ""Run 9"" and ""Run 13"": [Highest mean absolute error]";If we want to reproduce the results of previous runs, we need to retrieve the model. Which model was used for “Run 4”?;Return the run with the worst RMSE (Largest value);Where you used linear regression algorithm and the RMSE was less than 60;What was the R2 value of the very first run?;How helpful was the short tutorial in the beginning in completing the tasks?;How do you rate the ease of completing the tasks?;How helpful were the DVC commands to compare the runs?;How long did it take you to complete the DVC section?;Any Additional Comments:;Which run performed best, (i.e. has the lowest RMSE score)? ;What is the RMSE value for that run?;Which of the algorithms performed best in their first run? LR or RFR i.e. which one had the lowest RMSE.;What data features were used for the run with the lowest r2_score?;Between Run 4 and Run 1, which one had the highest mean absolute error?;And what was the value?;"Compare “Run 5”, “Run 7”, ""Run 9"" and ""Run 13"": [Highest RMSE]";"Compare “Run 5”, “Run 7”, ""Run 9"" and ""Run 13"": [Highest R2]";"Compare “Run 5”, “Run 7”, ""Run 9"" and ""Run 13"": [Highest mean absolute error]";If we want to reproduce the results of previous runs, we need to retrieve the model. Which model was used for “Run 4”?;Run with the worst RMSE (Largest value);Where you used linear regression algorithm and the RMSE was less than 6.5;What was the R2 value of the very first run?;How helpful was the short tutorial in the beginning in completing the tasks?;How do you rate the ease of completing the tasks?;Describe how you manually track, query, and retrieve the experiment runs and their assets.;How helpful was the use of your manual technique in tracking/retrieving the experimental runs and their assets?;How long did it take you to complete the No-Tool section?;Any Additional Comments:;Which of the 13 runs performed best? (i.e. which has the lowest RMSE score?);What is the RMSE value for that run?;Which of the algorithms (LR & RFR) performed best (lowest RMSE) in their first run?;What data features were used for the experimental run with the highest r2_score?;Compare Run 4 and Run 1, which one had the highest mean absolute error?;What was the value?;"Compare “EX-5” ,“EX-7”, ""EX-9"" and ""EX-13"" in the dashboard table. [Highest RMSE]";"Compare “EX-5” ,“EX-7”, ""EX-9"" and ""EX-13"" in the dashboard table. [Highest R2]";"Compare “EX-5” ,“EX-7”, ""EX-9"" and ""EX-13"" in the dashboard table. [Highest mean absolute error]";If we want to reproduce the results of previous runs, we need to retrieve the model. Which model was used for “EX-4”?;Query Neptune for the model with the worst RMSE (Largest value). Provide Run id, and the parameters used.;List all linear regression runs with RMSE value greater than 0.9. Provide Run id, and the r2 value for that run.;In the python file, print the R2 value of the very first run. What was the value?;How helpful was the brief Neptune tutorial provided ahead of this experiment?;How do you rate the ease of completing the tasks?;How helpful is the visual dashboard provided by Neptune.ai when comparing the experimental runs?;How long did it take you to complete the Neptune.ai section?;Any Additional Comments:;Describe your experience with each of the tools(Neptune, DVC, and No-Tool).;The DVC and Neptune tools provide a significant support for tracking, querying and retrieving generated data from ML experiments over No-tool.;Please elaborate on your response above.;Which tool do you consider best for tracking data during ML experiments ?;Which tool do you consider best for querying and retrieving previously tracked data?;Which of Neptune and DVC do you consider least intrusive in completing the tasks?;Which of Neptune and DVC was the easiest to learn?;Which of the tools provides the best support for comparing different experiment runs?;Neptune helps compare different runs using a web dashboard, while DVC uses CLI. Which do you most convenient?;Please elaborate.;Finally, which tool would you recommend a ML practitioner to use?;Please elaborate.;Which run performed best, (i.e. has the lowest RMSE score)? ;What is the RMSE value for that run?;Which of the algorithms performed best in their first run? LR or RFR i.e. which one had the lowest RMSE.;What data features were used for the run with the lowest r2_score?;Between Run 4 and Run 1, which one had the highest mean absolute error?;And what was the value?;"Compare “Run 5”, “Run 7”, ""Run 9"" and ""Run 13"": [Highest RMSE]";"Compare “Run 5”, “Run 7”, ""Run 9"" and ""Run 13"": [Highest R2]";"Compare “Run 5”, “Run 7”, ""Run 9"" and ""Run 13"": [Highest mean absolute error]";If we want to reproduce the results of previous runs, we need to retrieve the model. Which model was used for “Run 4”?;Run with the worst RMSE (Largest value);Where you used linear regression algorithm and the RMSE was less than 0.7;What was the R2 value of the very first run?;How helpful was the short tutorial in the beginning in completing the tasks?;How do you rate the ease of completing the tasks?;Describe how you manually track, query, and retrieve the experiment runs and their assets.;How helpful was your use of a manual technique in tracking/retrieving the experimental runs and their assets?;How long did it take you to complete the No-Tool section?;Any Additional Comments:;Which run performed best, (i.e. has the lowest RMSE score)? ;What is the RMSE value for that run?;Which of the algorithms performed best in their first run? LR or RFR i.e. which one had the lowest RMSE.;What data features were used for the run with the highest r2_score?;Between Run 4 and Run 1, which one had the highest mean absolute error?;What was the value?;"Compare “Run 5”, “Run 7”, ""Run 9"" and ""Run 13"": [Highest RMSE]";"Compare “Run 5”, “Run 7”, ""Run 9"" and ""Run 13"": [Highest R2]";"Compare “Run 5”, “Run 7”, ""Run 9"" and ""Run 13"": [Highest mean absolute error]";If we want to reproduce the results of previous runs, we need to retrieve the model. Which model was used for “Run 4”?;Return the run with the worst RMSE (Largest value);Where you used linear regression algorithm and the RMSE was less than 5;What was the R2 value of the very first run?;How helpful was the short tutorial in the beginning in completing the tasks?;How do you rate the ease of completing the tasks?;How helpful were the DVC commands to compare the runs?;How long did it take you to complete the DVC section?;Any Additional Comments:;Which of the 13 runs performed best? (i.e. which has the lowest RMSE score?);What is the RMSE value for that run?;Which of the algorithms (LR & RFR) performed best (lowest RMSE) in their first run?;What data features were used for the experimental run with the highest r2_score?;Compare Run 4 and Run 1, which one had the highest mean absolute error?;What was the value?;"Compare “EX-5” ,“EX-7”, ""EX-9"" and ""EX-13"" in the dashboard table. [Highest RMSE]";"Compare “EX-5” ,“EX-7”, ""EX-9"" and ""EX-13"" in the dashboard table. [Highest R2]";"Compare “EX-5” ,“EX-7”, ""EX-9"" and ""EX-13"" in the dashboard table. [Highest mean absolute error]";If we want to reproduce the results of previous runs, we need to retrieve the model. Which model was used for “EX-4”?;Query Neptune for the model with the worst RMSE (Largest value). Provide Run id, and the parameters used.;List all linear regression runs with RMSE value less than 54. Provide Run id, and the r2 value for that run.;In the python file, print the R2 value of the very first run. What was the value?;How helpful was the brief Neptune tutorial provided ahead of this experiment?;How do you rate the ease of completing the tasks?;How helpful is the visual dashboard provided by Neptune.ai when comparing the experimental runs?;How long did it take you to complete the neptune.ai section?;Any Additional Comments:;Describe your experience with each of the tools(Neptune, DVC and No-Tool).;The DVC and Neptune tools provide a significant support for tracking, querying and retrieving generated data from ML experiments over No-tool.;Please elaborate on your response above.;Which tool do you consider best for tracking data during ML experiments ?;Which tool do you consider best for querying and retrieving previously tracked data?;Which of Neptune and DVC do you consider least intrusive in completing the tasks?;Which of Neptune and DVC was the easiest to learn?;Which of the tools provides the best support for comparing different experiment runs?;Neptune helps compare different runs using a web dashboard, while DVC uses CLI. Which do you most convenient?;Please elaborate.;Finally, which tool would you recommend a ML practitioner to use?;Please elaborate.;
2021/08/05 7:44:51 pm EET;Student;B.Sc.;2 months;Yes;4;No;;;Group B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;Runs: 6 and 7;58.84;RFR;'s1','sex';Run 4;;Run 7;Run 5;Run 7;LinearRegression(normalize=False);run 3;run 6, True, run 7, True;0.07234;5;3;5;2+ hours;I prefer using CLI to track the assets, easy and short commands;run 5;Not sure;I don't know;not sure;I don't know;not sure;Run 5;Run 9;Run 5;LinearRegression(normalize=False);IDK;IDK;IDK;2;1;I did not track the data in any way, which made it difficult to complete the tasks;1;30 mins - 1 hour;;Run 7;0.512;RFR;Empty;Run 4;0.602;EX-5;EX-7;EX-5;LinearRegression(normalize=False);EX-5, normalize=False;EX-5: 0.3, EX-11: 0.3;0.50123;5;5;5;1 hour 30 mins - 2 hours;;Dvc was my favorite because it's run through the CLI, Neptune dashboard was good but the python file was too messy, no-tool was difficult to track;Strongly Agree;When using the no-tool, I found it hard to complete the tasks, whereas neptune and dvc helped me look for the answers;DVC;Neptune.ai;DVC;DVC;Neptune.ai;DVC (CLI);I use git a lot, so using dvc was not that different;DVC;Because it would take long to learn it, especially if you have a git background;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;0.01
2021/08/05 9:00:07 pm EET;Software Developer;B.Sc.;1;Yes;3;No;;;Group A;Run 1;5.4;LR;All available features;Run 1;3.19352;EX-5;EX-9;EX-5;LinearRegression(normalize=False);EX-2, noramlize: False;"EX-1: 0.680931,

EX-4: 0.555543,

EX-6: 0.658275";0.680931;5;5;4;1 hour - 1 hour 30 mins;;Run 1 and 2;0.80628;LR;Population', 'HouseAge';Run 4;0.9107;Run 13;Run 5;Run 13;LinearRegression(normalize=False);run 13, Parameters not used;run 1 and run 2;run 7: False, run 4: False, run 3: False;0.517835;4;4;4;1 hour - 1 hour 30 mins;;run 1 and run 2;53.10224;LR;Normalize=False;Run 4;53.9833879;Run 5;Run 13;Run 5;LinearRegression(normalize=False);run 4, 64.386816;run 1: 0.53880, run 2: 0.53880, run 13: 0.51104;0.5388;5;5;;5;1 hour-1 hour 30 mins;;Neptune provided a good visual interface while DVC had easy commands. DVC was more like git which I am quite used to. ;Strongly Agree;;DVC;DVC;DVC;DVC;DVC;Neptune (Web dashboards);Neptune allowed me to compare and visualise multiple runs;DVC;DVC because it's very similar to git so it is easy to learn and it would be faster for ML practitioners to run commands from the terminal.;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
2021/08/07 1:46:52 pm EET;Student;College;0;Yes;0.5;No;;;Group B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;run 7;58.8;RFR;'s1', 'sex';Run 4;64;Run 5;Run 13;Run 5;LinearRegression(normalize=False);run 3;run 6 and run 7: True;0.08;3;2;3;1 hour 30 mins - 2 hours;;run 7;5,2;I don't know;"n-estimate: 50, 
max-depth: 5,
min-samples: 6,
ccp: 0.1";Run 1;2,91;Run 13;Run 7;Run 9;LinearRegression(normalize=False);run 7,;not sure;0,6;1;1;I wrote most results on paper after printing them out.;1;1 hour - 1 hour 30 mins;;EX7;0,51247;RFR;No features used, commented out;Run 4;;EX-5;EX-7;EX-5;LinearRegression(normalize=False);EX5, False;"EX2: 0.247, 
EX5: 0.1572";0,606;4;4;5;1 hour 30 mins - 2 hours;;"Neptune helped me answer the questions easily, 
DVC was good, but hard to compare different runs from terminal,
No-Tool was hard to keep record of the different results";Strongly Agree;I didnt have to think about writing anything down, it was saved with the tool;Neptune.ai;Neptune.ai;Neptune.ai;Neptune.ai;Neptune.ai;Neptune (Web dashboards);DVC doesn't let you compare different runs at once, whereas neptune lets you compare specefic results visually;Neptune.ai;I found it easier to learn the neptune tool, and it allowed me to answer the questions confidently ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;0,01
2021/08/07 4:46:38 pm EET;Student;B.Sc.;1;Yes;4;No;;;Group C;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;run 1 and 2;0,7254;LR;df[['AveRooms', 'HouseAge', 'AveBedrms', 'Latitude']];Run 1;0,531;Run 13;Run 9;Run 13;LinearRegression();run 9, 1,0808;run 1, 2 0.6064;0.6064;2;2;"I printed the results out for every run.
print('run: 1')
print('rmse: {0}'.format(rmse))
print('r2: {0}'.format(r2))
print('MAE: {0}'.format(mean_absolute_error))";4;1 hour-1 hour 30 mins;;run 9;4,6728;RFR;"""RAD"", ""LSTAT"", ""PTRATIO""";Run 4;4.22;Run 5;Run 9;Run 5;LinearRegression();run 4: noramlize: false;run8: none, run 9: n_estimator: 50, max_depth: 5, minsamples: 6, ccp: 0.1, max:feature:auto, run 10: n_estimator: 50, max_depth: 5, minsamples: 6, ccp: 0.01, max:feature:auto;0,6166;3;2;4;1 hour 30 mins - 2 hours;;EX-1;53,1022;LR;53,1022;Run 4;53,98;EX-7;EX-5;EX-7;LinearRegression();EX-4, normalize:false;EX-1, 0.5388;0.5388;5;4;5;1 hour - 1 hour 30 mins;;Neptune helped me answer the questions much quicker, dvc was simple in terms of using cmd, no tool was toughest;Strongly Agree;I didn't have to copy and paste the values;Neptune.ai;Neptune.ai;Neptune.ai;Neptune.ai;Neptune.ai;Neptune (Web dashboards);The dashboard let me query all the answers very quickly, for dvc I had to look into every run ;Neptune.ai;Nepune made it easier to compare multiple runs which saves a lot time;
2021/08/08 7:25:36 pm EET;Student/ Developer;B.Sc.;0,5;Yes;5;No;;;Group A;EX-1;5.378;LR;'CRIM', 'TAX', 'RM';Run 1;3.19;EX-5;EX-9;EX-5;LinearRegression(normalize=False);EX-3, normalize=False;"EX-1: 0.6809,
EX-4: 0.5555";0.68;4;4;4;1 hour 30 mins - 2 hours;Neptune I think is a good tool to train or analyze models like you created;Run-1 and Run-2;0.806;LR;Population;Run 4;0.91;Run 13;Run 7;Run 13;LinearRegression(normalize=False);run-6, False;run-1 and run-2;0.93996, False;0.518;3;3;3;1 hour - 1 hour 30 mins;I liked the ease of writing commands on the prompt, but there was no way of comparing different runs;run 6;52.5313;RFR;normalize=True;I don't know;;Run 9;Run 7;Run 9;LinearRegression(normalize=False);run 8, 63.4245;run 6, 0.5334;0.5388;2;2;I tried to write down most values with the runs, was unsure about the accuracy ;2;1 hour-1 hour 30 mins;;Neptune was very straightforward, although I had to look at the documentation a lot. Dvc had simpler commands but couldn't compare more than two runs. No tool was too hard to track.;Strongly Agree;;Neptune.ai;Neptune.ai;DVC;DVC;Neptune.ai;Neptune (Web dashboards);The we dashboards provided a nice GUI which helped me complete the tasks.;Neptune.ai;When it comes to simplicity I would say DVC, however , completing the tasks with less fuss I would be prefer Neptune;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
2021/08/09 12:39:21 am EET;Student;B.Sc.;0.5;Yes;2;No;;;Group A;Run 1;5.37911;LR;All;Run 1;3.19350;EX-5;EX-9;EX-5;LinearRegression(normalize=False);EX-2, Normalize, False;"EX-1 - 0.680931
EX-4 - 0.555543,
EX-6 - 0.658275";0.680931;4;4;4;1 hour - 1 hour 30 mins;;Run 1 & Run 2;0.80628;LR;'Population', 'HouseAge';Run 4;0.9108;Run 13;Run 5;Run 13;LinearRegression(normalize=False);Run 13, No parameters;Run 1 & Run 2;Run 7 - False Run 4 - False Run 3 - False;0.517835;4;5;5;1 hour - 1 hour 30 mins;;Run 1 & Run 2;53.10224;LR;normalize=False;Run 4;53.9833879;Run 5;Run 13;Run 5;LinearRegression(normalize=False);Run 4, 64.386816;Run 1 - 0.53880, Run 2 - 0.53880, Run 13 - 0.51104;0.5388;3;2;;3;1 hour-1 hour 30 mins;;"Neptune - Great UI, Good Usability, Not quick to use
DVC - Quick to use, Robust Operation, A little less usable
No-Tool - Difficult";Strongly Agree;;DVC;DVC;DVC;Neptune.ai;DVC;DVC (CLI);;DVC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
2021/08/10 7:12:33 pm EET;Student;B.Sc.;1;Yes;3;No;;;Group A;1;5.378;LR;"
'CRIM', 'TAX', 'RM'";Run 1;3.19;EX-5;EX-9;EX-5;LinearRegression(normalize=False);0.01;"Ex-1= 0.68,
Ex-4 = 0.56
Ex-6 = 0.66";0.68;4;4;5;1 hour 30 mins - 2 hours;;1 and 2;0.806;LR;Population and HouesAge;Run 4;0.91;Run 13;Run 5;Run 13;LinearRegression(normalize=False);run 13, none;run-1 , and run-2;run-7 = False, run-4 = False, run-3 = False;0.517;3;3;3;1 hour 30 mins - 2 hours;;1 and 2;53.1;RFR;normalize=False;Run 4;53.98;Run 5;Run 13;Run 5;LinearRegression(normalize=False);run 5 = 64.386;run 1 = 0.538, run 2 = 0.538, run 13 = 0.511;0.538;2;1;I printed out the values and copied them to a document;4;1 hour 30 mins-2 hours;;Neptune was my favorite, as it helped me complete the questions easily. DVC helped but I had to manually look for the answers by process of elimination. No-Tool took too long;Strongly Agree;You can run the script without worrying about saving the data, as opposed to the no tool, where I had to write down each value after every run.;Neptune.ai;Neptune.ai;DVC;DVC;Neptune.ai;Neptune (Web dashboards);I think Neptune because I had less stress answering the questions, but when it comes to tracking it becomes quite tedious, script becomes too long.  DVC wasn't as effective as neptune when comparing results.;Neptune.ai; Neptune helped in answering all questions easily, the tracking process was quite tedious. ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
2021/08/14 3:15:06 pm EET;Student;B.Sc.;.5;Yes;3;No;;;Group A;run 1;5.38;LR;CRIM, TAX, RM;Run 4;3.77179;EX-5;EX-9;EX-5;LinearRegression(normalize=False);EX-2 , False;"EX-1 - 0.680931
EX-4 - 0.555543,
EX-6 - 0.658275";0.68;4;4;4;1 hour 30 mins - 2 hours;Neptune was easy to use except for the setting up which took time;run 2;0.81;LR;Population and houseage;Run 4;0.91;Run 9;Run 7;Run 9;LinearRegression(normalize=True);run 12;run 2;run 3, 4, 7;0.518;2;3;3;1 hour 30 mins - 2 hours;;run 6;22.1457;LR;age, sex, bmi;Run 1;50.722;Run 9;Run 7;Run 9;LinearRegression(normalize=False);run 8;63.42;r2 = 0.51;1;1;I printed most values and then wrote them on paper ;2;1 hour-1 hour 30 mins;;"Neptune- very nice UI, easy to compare different runs, took time to get used to it
dvc- easy to set it up, but hard to compare results from cmd
notool- was hard keep track of all values, time consuming";Agree;I believe neptune helped me answer the questions effortlessly, ;Neptune.ai;Neptune.ai;Neptune.ai;DVC;Neptune.ai;Neptune (Web dashboards);Answering the questions was less tedious than DVC, because I could easily look for the answer through the dashboard;Neptune.ai;Neptune, only downside is that it takes time to get used to it, otherwise very good for comparing;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
2021/08/14 3:57:08 pm EET;Student ;B.Sc.;2 months;Yes;3;No;;;Group C;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;run 3;0.725;I don't know;Averooms, housage, avebedrooms;Run 4;.502;Run 9;Run 7;Run 9;LinearRegression();run 10, 0.35;none;0.606;1;2;I tried to print most values for each run;3;1 hour-1 hour 30 mins;;run 7;0.58;RFR;'RAD', 'LSTAT', 'PTRATIO';Run 1;4.012;Run 5;Run 13;Run 5;LinearRegression();run 3, True;run 8: none, run 9: n_estimator: 50, max_depth: 5, minsamples: 6, ccp: 0.1, max:feature:auto, minsamples: 6,;0.6166;3;3;3;1 hour - 1 hour 30 mins;;EX-1;53.1;LR;age, sex, bmi;Run 4;53.983;EX-7;EX-5;EX-7;LinearRegression();EX-4, False;EX-1  r2 = 0.538803;0.538803;5;5;4;1 hour 30 mins - 2 hours;;"No-tool:time consuming
dvc: easy to understand
Neptune: easier to answer the question, ";Strongly Agree;I didn't need to manually record anything with neptune, just ran the code and the tool tracks for me.;DVC;Neptune.ai;DVC;DVC;Neptune.ai;Neptune (Web dashboards);extracting answers was easier with neptune;Neptune.ai;Although I liked dvc due to the similarity it has with git, neptune provided more ease when answering questions.;
2021/08/15 12:13:55 pm EET;Student ;B.Sc.;0.5;Yes;3;No;;;Group B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;run 6;58.8;RFR;s1, sex;Run 4;64.4;Run 9;Run 13;Run 9;LinearRegression(normalize=False);run 3;run 6,7 , True;0.0811;3;3;3;1 hour 30 mins - 2 hours;;run 12;4.5402;LR;FALSE;I don't know;not sure;Run 5;Run 7;Run 5;LinearRegression(normalize=False);run 5, 7.568;run 2: 0.680931 run 6:0.658275;0.68;2;1;I didnt do anything at first,reran the experiment and printed the data for each run;2;1 hour 30 mins - 2 hours;;EX7;0.512472;RFR;No features used, was commented out;Run 4;0.60287;EX-5;EX-7;EX-5;LinearRegression(normalize=False);EX5, False;"EX2: 0.24703
EX5: 0.15719";0.606441;4;4;5;1 hour - 1 hour 30 mins;;"DVC: easy to use, but hard to complete the tasks
no-tool: hard to provide answers, had to redo the runs to keep track of data
Neptune: by far the best to USE, but took a while to setup
";Strongly Agree;Compared to no-tool, using neptune and dvc made it easier. Although, neptune was the best imo;Neptune.ai;Neptune.ai;Neptune.ai;DVC;Neptune.ai;Neptune (Web dashboards);"For neptune it was easy to query various data, took a matter of seconds.
Whereas, with dvc i had toscroll through the cli";Neptune.ai;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
2021/08/15 3:02:06 pm EET;Student ;B.Sc.;1;Yes;4;No;;;Group C;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;run 1 and 2;0.725;LR;'AveRooms', 'HouseAge', 'AveBedrms', 'Latitude';Run 4;0,531;Run 9;Run 7;Run 9;LinearRegression();run 9 = 1,081;run 1 and 2 = 0.6064;0.606;2;3;Print the values in command line;3;30 mins-1 hour;;run 9;4.673;RFR;'RAD', 'LSTAT', 'PTRATIO';Run 4;4.22;Run 5;Run 7;Run 5;LinearRegression();run 4 = false;run8: no param and run 9: n_estimator: 50, max_depth: 5, minsamples: 6, ccp: 0.1, max:feature:auto, run 10: n_estimator: 50, max_depth: 5, minsamples: 6, ccp: 0.01, max:feature:auto;0,6166;4;4;4;1 hour 30 mins - 2 hours;;EX1;53.1022;LR;age, sex, bmi;Run 4;53.983;EX-7;EX-5;EX-7;LinearRegression();EX-4, normalize False;EX-1, 0.539;0.539;5;4;5;1 hour 30 mins - 2 hours;;"dvc: was easy to understand as I am familiar with git
neptune: was very good when completing the tasks
no-tool: took to much time to wrtie down the results";Strongly Agree;Copying the results after every change was quite annoying, and I was unsure about about most answers for the no tool section;DVC;Neptune.ai;Neptune.ai;DVC;Neptune.ai;Neptune (Web dashboards);When it comes to the easist to get started with, I would say DVC but as for the neptune it took a few runs before I understood how the tool works, but comparing different runs it has the edge over dvc.;DVC;If you're familiar with git, then dvc will be very useful as it doesn't require much time to get used to, plus it keeps everything simple by running commands on the command line;
2021/08/15 3:07:13 pm EET;Student ;B.Sc.;2 months;Yes;2;No;;;Group C;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;run 4;0.7834;I don't know;'AveRooms', 'HouseAge';I don't know;;Run 13;Run 9;Run 13;LinearRegression();run 8 = 1.453;not sure;0.61;1;1;Printed the values for most runs, hard to rverse the experiment ;1;1 hour 30mins-2 hours;;run 3;4.721;RFR;'RM', 'LSTAT', 'PTRATIO';Run 1;4.542;Run 5;Run 9;Run 5;LinearRegression();run 7, false;not sure;0.6166;3;3;3;1 hour 30 mins - 2 hours;;EX1;53.1022;LR;"age 
sex 
bmi";Run 4;53.98;EX-7;EX-5;EX-7;LinearRegression();EX-4, False;"EX-1
r2 = 0.5388";0.5388;4;4;5;1 hour 30 mins - 2 hours;;DVC made sense apart from tracking the different data, I felt it was too much to create a tag for every change. As for the neptune tool, I felt like it took too long to prepare the data, but once the runs began it was very easy from thereon.;Agree;No-tool was by far the hardest phase as I was required to do what neptune does manually;Neptune.ai;Neptune.ai;Neptune.ai;DVC;Neptune.ai;Neptune (Web dashboards);I feel that neptune is best once you know how to use the tool.;Neptune.ai;Very easy to retrieve data.;
2021/08/15 4:36:28 pm EET;Student, freelance;High School;very short;Yes;3 months;No;;;Group C;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;run 8;0.75327;RFR;Averooms and houseage;Run 1;0.516386;Run 5;Run 9;Run 5;LinearRegression();runn 8 1.063;dont know;0.61;2;2;I guessed for the most part, printed some runs only;1;1 hour 30mins-2 hours;;run 2;0.53;LR;'RAD', 'LSTAT';I don't know;dont know;Run 7;Run 9;Run 7;LinearRegression();run 4 false;dont know;0.617;3;4;3;1 hour 30 mins - 2 hours;;ex1;53.1022;LR;age, sex, bmi;Run 4;53.983;EX-9;EX-5;EX-9;LinearRegression();EX-4, normalize = false;ex-1 r2 = 0.5388;0.5388;4;4;4;1 hour 30 mins - 2 hours;;Neptune was easy to use;Strongly Agree;I see the difference when not using the tools, answering the questions becomes harder;Neptune.ai;Neptune.ai;Neptune.ai;Neptune.ai;Neptune.ai;Neptune (Web dashboards);;Neptune.ai;;
2021/08/15 5:08:22 pm EET;Software Student;B.Sc.;1;Yes;5;No;;;Group B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;run 6 and 7;58.84;RFR;;Run 4;64.433;Run 5;Run 9;Run 5;LinearRegression(normalize=False);;run 6 and 7 = True , run 13, None used;0.08112;4;4;4;1 hour - 1 hour 30 mins;straight forward;run 13;4.4403;LR;not sure;I don't know;;Run 9;Run 13;Run 9;LinearRegression(normalize=False);run 9, RMSE = 7.568;;0.681;4;5;printed the values of mean, r2 and rmse in console and wrote down changes in code for each run on the paper for tracking;4;1 hour - 1 hour 30 mins;;7;0.512472;RFR;No features;Run 4;0.60287;EX-5;EX-7;EX-5;LinearRegression(normalize=False);run 5 normalize = False;(run 2: 0.247033) , (run 5: 0.15719);0.606441;3;2;3;1 hour 30 mins - 2 hours;;"Neptune had a good GUI but the querying part was a bit confusing specially for somebody who never used the tool before.

DVC was pretty straight forward and the show command was all i needed to track the changes

Not-tool > Straight forward as the DVC but needed to store the metrics manually by writing it down";Agree;Neptune and dvc is good for removing the manual work by the developer to keep track of the metrics and errors etc.;DVC;DVC;Neptune.ai;DVC;Neptune.ai;DVC (CLI);Im used to use git from the terminal and using dvc through terminal provided a similar experience for me thus making it much easier to get started with.;Neptune.ai;I would recommend Neptune as it has much more potential than dvc in terms of querying different runs and it can get much more easier and handy for people who are not familiar with terminal practices.;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
2021/08/15 9:02:30 pm EET;Developer;B.Sc.;1 month;Yes;5;No;;;Group B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;run12;65.3608;RFR;;Run 4;64.43281;Run 9;Run 13;Run 9;LinearRegression(normalize=False);run 9;run 13  log2;0.08112;4;3;5;0 - 30 mins;The whole process could be automated using some bash commands and it could generate the reports. However I used this tool for the first time and it is easy to use.;run 5;not sure;LR;;Run 4;;Run 5;Run 7;Run 5;LinearRegression(normalize=False);;;;2;1;didnt know what to do;2;1 hour - 1 hour 30 mins;;EX7;0.51247;RFR;;Run 1;;EX-5;EX-7;EX-5;LinearRegression(normalize=False);EX5  norm = False;;0.606;4;4;5;1 hour 30 mins - 2 hours;;I prefer DVC;Strongly Agree;;DVC;DVC;DVC;DVC;DVC;DVC (CLI);;DVC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
